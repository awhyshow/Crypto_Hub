{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##CRYPTOINSIGHTHUB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "!pip install arch\n",
        "!pip install tabulate\n",
        "!pip install matplotlib seaborn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ZQX5EojinGsU"
      },
      "outputs": [],
      "source": [
        "API_KEY = \"CG-e5nkKqYuns3bSAoYNrDqFY8P\"   \n",
        "\n",
        "def fetch_coin_data(coin_id, days=90, max_retries=5):\n",
        "    url = f\"https://api.coingecko.com/api/v3/coins/{coin_id}/market_chart\"\n",
        "    params = {'vs_currency':'usd','days':days,'interval':'daily'}\n",
        "    headers = {\"x-cg-api-key\": API_KEY}\n",
        "\n",
        "    retries = 0\n",
        "    while retries < max_retries:\n",
        "        try:\n",
        "            response = requests.get(url, params=params, headers=headers, timeout=10)\n",
        "            response.raise_for_status()\n",
        "            data = response.json()\n",
        "            break  # success\n",
        "        except requests.exceptions.HTTPError as e:\n",
        "            if response.status_code == 429:\n",
        "                retries += 1\n",
        "                wait_time = 2 ** retries  # exponential backoff\n",
        "                print(f\"Rate limit hit, retrying in {wait_time}s...\")\n",
        "                time.sleep(wait_time)\n",
        "            else:\n",
        "                raise RuntimeError(f\"Failed to fetch data for {coin_id}: {e}\")\n",
        "        except Exception as e:\n",
        "            raise RuntimeError(f\"Failed to fetch data for {coin_id}: {e}\")\n",
        "\n",
        "  # --- Prices (approx OHLC) ---\n",
        "    prices = pd.DataFrame(data['prices'], columns=['Date', 'Close'])\n",
        "    prices['Date'] = pd.to_datetime(prices['Date'], unit='ms')\n",
        "    prices['Open'] = prices['Close']\n",
        "    prices['High'] = prices['Close']\n",
        "    prices['Low'] = prices['Close']\n",
        "\n",
        "    # --- Market Cap ---\n",
        "    market_cap = pd.DataFrame(data['market_caps'], columns=['Date', 'Market Cap'])\n",
        "    market_cap['Date'] = pd.to_datetime(market_cap['Date'], unit='ms')\n",
        "\n",
        "    # --- Volume ---\n",
        "    volume = pd.DataFrame(data['total_volumes'], columns=['Date', 'Volume'])\n",
        "    volume['Date'] = pd.to_datetime(volume['Date'], unit='ms')\n",
        "\n",
        "    # --- Merge ---\n",
        "    df = prices.merge(market_cap, on='Date').merge(volume, on='Date')\n",
        "    df['Coin'] = coin_id.capitalize()\n",
        "\n",
        "    df = df[['Coin', 'Date', 'Open', 'High', 'Low', 'Close', 'Market Cap', 'Volume']]\n",
        "    df = df.sort_values('Date').reset_index(drop=True)\n",
        "\n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "###Fetching Coin Data from the API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "btc_df = fetch_coin_data('bitcoin')\n",
        "time.sleep(2)\n",
        "eth_df = fetch_coin_data('ethereum')\n",
        "time.sleep(2)\n",
        "car_df = fetch_coin_data('cardano')\n",
        "time.sleep(2)\n",
        "dog_df = fetch_coin_data('dogecoin')\n",
        "\n",
        "all_df = pd.concat([btc_df, eth_df, car_df, dog_df], ignore_index=True)\n",
        "\n",
        "pd.set_option('display.float_format', '{:,.2f}'.format)\n",
        "\n",
        "print(all_df.head(10).to_markdown(tablefmt=\"grid\"))\n",
        "\n",
        "#added delay between request inorder to avoide 429 error\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "y8DCOK_VwcEf"
      },
      "outputs": [],
      "source": [
        "#add_realized_volatility calculates volatility based on the historical data of the asset's price\n",
        "def add_realized_volatility(df, window=30): #Rolling Standard Deviation → Realized Volatility\n",
        "    df = df.sort_values(\"Date\")\n",
        "    df['LogReturn'] = np.log(df['Close'] / df['Close'].shift(1))\n",
        "    df['RealizedVol'] = df['LogReturn'].rolling(window).std() * np.sqrt(365)  # represents how the market has been over a period of time\n",
        "    return df\n",
        "\n",
        "\n",
        "def add_atr(df, window=14): #Average True Range (ATR) → Calc Intraday Volatility\n",
        "    df = df.sort_values(\"Date\")\n",
        "    df['H-L'] = df['High'] - df['Low']\n",
        "    df['H-PC'] = (df['High'] - df['Close'].shift(1)).abs()\n",
        "    df['L-PC'] = (df['Low'] - df['Close'].shift(1)).abs()\n",
        "    df['TR'] = df[['H-L', 'H-PC', 'L-PC']].max(axis=1)\n",
        "    # True Range = max of (High-Low, High-prevClose, Low-prevClose)\n",
        "    df['ATR'] = df['TR'].rolling(window).mean()# Rolling ATR helps to measure risk and stoploss\n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "c2ad70_BtBe0"
      },
      "outputs": [],
      "source": [
        "from arch import arch_model\n",
        "\n",
        "def estimate_garch(df):\n",
        "    from arch import arch_model\n",
        "    returns = df['LogReturn'].dropna() * 100  # percentage returns\n",
        "    am = arch_model(returns, vol='Garch', p=1, q=1)\n",
        "    res = am.fit(disp='off')\n",
        "    # create full length series with NaN for first missing returns\n",
        "    garch_vol = pd.Series(index=df.index, data=np.nan)\n",
        "    garch_vol.iloc[len(df) - len(res.conditional_volatility):] = (\n",
        "        res.conditional_volatility / 100  # scale back to decimal\n",
        "    ) \n",
        "    df['garch_vol'] = garch_vol\n",
        "    return df, res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "pKS2lo1XyfLT"
      },
      "outputs": [],
      "source": [
        "btc_df = add_realized_volatility(btc_df)\n",
        "btc_df = add_atr(btc_df)\n",
        "btc_df, btc_garch = estimate_garch(btc_df)\n",
        "\n",
        "eth_df = add_realized_volatility(eth_df)\n",
        "eth_df = add_atr(eth_df)\n",
        "eth_df, eth_garch = estimate_garch(eth_df)\n",
        "\n",
        "car_df = add_realized_volatility(car_df)\n",
        "car_df = add_atr(car_df)\n",
        "car_df, car_garch = estimate_garch(car_df)\n",
        "\n",
        "dog_df = add_realized_volatility(dog_df)\n",
        "dog_df = add_atr(dog_df)\n",
        "dog_df, dog_garch = estimate_garch(dog_df)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "all_df = pd.concat([btc_df, eth_df, car_df, dog_df], ignore_index=True)\n",
        "all_df = all_df.sort_values(['Coin', 'Date']).reset_index(drop=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(car_df.head().to_markdown(tablefmt=\"grid\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "folder = \"Data\"\n",
        "\n",
        "btc_df = pd.read_csv(f\"{folder}/btc_df_saved.csv\")\n",
        "eth_df = pd.read_csv(f\"{folder}/eth_df_saved.csv\")\n",
        "car_df = pd.read_csv(f\"{folder}/car_df_saved.csv\")\n",
        "dog_df = pd.read_csv(f\"{folder}/dog_df_saved.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "for df in [btc_df, eth_df, car_df, dog_df]:\n",
        "    df['Date'] = pd.to_datetime(df['Date'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "btc_df.dtypes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "with open(\"Data/btc_garch_model.pkl\", \"rb\") as f:\n",
        "    btc_garch = pickle.load(f)\n",
        "\n",
        "with open(\"Data/eth_garch_model.pkl\", \"rb\") as f:\n",
        "    eth_garch = pickle.load(f)    \n",
        "\n",
        "with open(\"Data/car_garch_model.pkl\", \"rb\") as f:\n",
        "    car_garch = pickle.load(f)    \n",
        "\n",
        "with open(\"Data/dog_garch_model.pkl\", \"rb\") as f:\n",
        "    dog_garch = pickle.load(f)\n",
        "#arch models cannot be saved with pickle directly unless you extract the model results.\n",
        "#Use the built-in save() method"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
